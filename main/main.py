# -*- coding: utf-8 -*-
"""ТИНЬКОФ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S3jrDm9OGY9Ki5DjBqAkqv9LVgMJ16oK

Этот блок — фундамент всего скрипта. Здесь собраны все настройки и подготовительные шаги.

1.   Импорты: Мы подключаем все необходимые библиотеки (pandas, matplotlib, seaborn и др.).
2.   НКонфигурация: С помощью dataclass Config мы задаем все ключевые параметры в одном месте: пути к файлам, разделители, названия выходных папок. Это делает код гибким — чтобы адаптировать его под новые данные, достаточно поменять значения здесь.
3. Настройка среды: Мы создаем папки для результатов и настраиваем глобальный стиль графиков, чтобы они выглядели одинаково и профессионально во всем проекте.
"""

#Imports
from __future__ import annotations
import os, sys, io, json, base64, textwrap, math, warnings, statistics
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, Dict, List, Tuple
from operator import attrgetter

import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import nbformat as nbf
from nbformat.v4 import new_notebook, new_code_cell, new_markdown_cell

try:
    import seaborn as sns
    _HAS_SEABORN = True
except Exception:
    _HAS_SEABORN = False

#Configuration
@dataclass
class Config:
    csv_path: str = "/content/drive/MyDrive/Colab Notebooks/dano_dataset_travel.csv"   # путь к датасету
    sep: str = ";"
    encoding: str = "utf-8"
    out_dir: Path = Path("tbank_travel_eda")
    figs_dpi: int = 170
    max_sample_hist: int = 250_000
    ipynb_path: Path = Path("TBank_Travel_EDA.ipynb")
    html_path: Path = Path("TBank_Travel_EDA_Report.html")
    random_state: int = 42

CFG = Config()

#Environment Setup
np.random.seed(CFG.random_state)

# Создание выходных директорий
CFG.out_dir.mkdir(parents=True, exist_ok=True)
(CFG.out_dir / "png").mkdir(exist_ok=True)
(CFG.out_dir / "svg").mkdir(exist_ok=True)
(CFG.out_dir / "csv").mkdir(exist_ok=True)

# Глобальные настройки matplotlib
matplotlib.rcParams.update({
    "figure.figsize": (9.6, 5.0),
    "figure.dpi": 120,
    "axes.grid": True,
    "grid.alpha": 0.25,
    "axes.titleweight": "bold",
    "axes.titlesize": 13,
    "axes.labelsize": 11,
    "xtick.labelsize": 10,
    "ytick.labelsize": 10,
    "font.family": "DejaVu Sans",
})

if _HAS_SEABORN:
    sns.set_theme(context="notebook", style="ticks")

"""Здесь мы определяем все вспомогательные функции, которые будут многократно использоваться в проекте. Это хорошая практика, которая помогает избежать дублирования кода (Don't Repeat Yourself) и делает основной скрипт более читаемым.
В этот блок входят утилиты для:

*   Форматирования чисел, процентов и дат.
*   Сохранения графиков в нескольких форматах (PNG, SVG).
*   Кодирования изображений для встраивания в HTML-отчет.
*   Подбора оптимального числа корзин для гистограмм (nice_bins).

*   Приведения колонок к числовому типу с очисткой от "мусора".

"""

def _fmt_int(n: Optional[float]) -> str:
    if n is None or (isinstance(n, float) and (np.isnan(n) or np.isinf(n))):
        return "—"
    return f"{int(n):,}".replace(",", " ")

def _fmt_float(n: Optional[float], p: int = 1) -> str:
    if n is None or (isinstance(n, float) and (np.isnan(n) or np.isinf(n))):
        return "—"
    return f"{n:.{p}f}"

def _fmt_pct(x: Optional[float], p: int = 1) -> str:
    if x is None or (isinstance(x, float) and (np.isnan(x) or np.isinf(x))):
        return "—"
    return f"{x*100:.{p}f}%"

def savefig(fig: matplotlib.figure.Figure, name: str, tight: bool = True) -> Tuple[Path, Path]:
    png_path = CFG.out_dir / "png" / f"{name}.png"
    svg_path = CFG.out_dir / "svg" / f"{name}.svg"
    if tight:
        fig.tight_layout()
    fig.savefig(png_path, dpi=CFG.figs_dpi, bbox_inches="tight")
    fig.savefig(svg_path, bbox_inches="tight")
    print(f"[saved] {png_path.name} / {svg_path.name}")
    return png_path, svg_path

def img_to_base64(path: Path) -> str:
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode("ascii")

def coerce_numeric(series: pd.Series) -> pd.Series:
    return pd.to_numeric(
        series.astype(str).str.replace(" ", "", regex=False)
              .str.replace("\xa0","", regex=False)
              .str.replace(",", ".", regex=False),
        errors="coerce"
    )

def nice_bins(series: pd.Series, target_bins=40) -> int:
    n = series.dropna().shape[0]
    if n <= 0:
        return 10
    try:
        iqr = np.subtract(*np.percentile(series.dropna(), [75, 25]))
        h = 2 * iqr * (n ** (-1/3)) if iqr > 0 else None
        if h:
            bins = int((series.max() - series.min()) / max(h, 1e-9))
            return max(10, min(100, bins))
    except Exception:
        pass
    return min(80, max(15, int(np.sqrt(n))))

def annotate_bars(ax, fmt: str = "{:.1f}%", yshift: float = 0.01):
    for p in ax.patches:
        height = p.get_height()
        ax.annotate(fmt.format(height), (p.get_x() + p.get_width()/2., height),
                    ha='center', va='bottom', xytext=(0, ax.get_ylim()[1]*yshift),
                    textcoords='data', fontsize=9)

def ecdf(series: pd.Series) -> Tuple[np.ndarray, np.ndarray]:
    x = np.sort(series.dropna().values)
    y = np.arange(1, len(x)+1) / len(x) if len(x) else np.array([])
    return x, y

def qscore(series: pd.Series, q: int = 5, reverse: bool = False) -> pd.Series:
    ranks = series.rank(method="first", na_option="bottom")
    try:
        bins = pd.qcut(ranks, q=q, labels=False, duplicates="drop") + 1
    except Exception:
        bins = pd.Series(1, index=series.index, dtype="float64")
    if reverse:
        bins = q + 1 - bins
    return bins.fillna(0).astype(int)

"""  Это ключевой этап подготовки данных. Вся работа с "сырым" датасетом происходит здесь. Блок выполняет три основные задачи:

1. Загрузка: Чтение CSV-файла в DataFrame с помощью pandas.read_csv.
2. Очистка и приведение типов: Преобразование колонок с датами в формат datetime, числовых колонок — в numeric (с обработкой ошибок и форматов), а флагов — в булев (True/False) тип.
3. Создание признаков (Feature Engineering): Расчет новых, полезных для анализа колонок, таких как is_success (успешный ли заказ), lead_time_days (время до начала бронирования) и stay_nights (длительность проживания).
"""

print(f"[load] {CFG.csv_path}")
df = pd.read_csv(CFG.csv_path, sep=CFG.sep, encoding=CFG.encoding, low_memory=False)

DATE_COLS = [
    "party_first_order_dt","party_first_order_type_dt","free_cancel_booking_dttm",
    "created_dttm","cancel_dttm","book_start_dttm","local_book_start_dttm","book_end_dttm",
    "last_sms_dt","last_email_send_dt","last_session_dttm"
]
for c in DATE_COLS:
    if c in df.columns:
        df[c] = pd.to_datetime(df[c], errors="coerce")

NUM_COLS = ["promo_code_discount_amt","loyalty_accrual_rub_amt",
            "nominal_price_eur_amt","nominal_price_rub_amt","monthly_income_amt"]
for c in NUM_COLS:
    if c in df.columns:
        df[c] = coerce_numeric(df[c])

FLAG_COLS = [c for c in df.columns if c.endswith("_flg")]
for c in FLAG_COLS:
    df[c] = pd.to_numeric(df[c].astype(str).str.replace(",", ".", regex=False), errors="coerce")
    df[c] = (df[c].fillna(0) > 0)

df["order_type"] = df.get("order_type_cd", pd.Series(index=df.index)).map({"AIR":"Авиабилеты","HOT":"Отели"}).fillna(df.get("order_type_cd"))
df["is_success"] = df.get("order_status_cd","").eq("SUC")
df["order_date"]  = df["created_dttm"].dt.date
df["order_month"] = df["created_dttm"].dt.to_period("M").astype(str)
df["dow"]  = df["created_dttm"].dt.dayofweek
df["hour"] = df["created_dttm"].dt.hour
df["lead_time_days"] = (df["book_start_dttm"] - df["created_dttm"]).dt.days
df["stay_nights"]    = (df["book_end_dttm"]   - df["book_start_dttm"]).dt.days
df.loc[df.get("order_type_cd")!="HOT", "stay_nights"] = np.nan

def lead_bucket(x: float) -> str:
    if pd.isna(x): return "NA"
    if x <= 0: return "0d"
    if x <= 3: return "1-3d"
    if x <= 7: return "4-7d"
    if x <= 14: return "8-14d"
    if x <= 30: return "15-30d"
    return "31+d"
df["lead_bucket"] = df["lead_time_days"].map(lead_bucket)

if "age" in df.columns:
    df["age"] = coerce_numeric(df["age"])
if "children_cnt" in df.columns:
    df["children_cnt"] = coerce_numeric(df["children_cnt"])

"""Сердце нашего исследования. Здесь мы проводим разведочный анализ данных (EDA), чтобы найти первые инсайты, закономерности и аномалии.
Блок включает в себя:
1. Обзор данных: Вывод основной информации о размере датасета, временном периоде и распределении заказов.
2. Расчет сводных таблиц: Агрегация данных для получения ключевых метрик (средний чек, конверсия по типам) и их сохранение в CSV-файлы.
3. Построение графиков: Визуализация данных для наглядного представления. Мы строим динамику заказов, распределения цен, гистограммы и тепловые карты, чтобы ответить на основные вопросы о поведении пользователей.
"""

rows, cols = df.shape
period = (str(df["created_dttm"].min())[:10], str(df["created_dttm"].max())[:10])
by_type = df["order_type"].value_counts(dropna=False)

print(f"[shape] {rows:,} rows x {cols} cols".replace(",", " "))
print(f"[period] {period[0]} … {period[1]}")
print("[types]\n", by_type)

summary_by_type = df.groupby("order_type", dropna=False).agg(
    orders=("order_rk","count"),
    success_rate=("is_success","mean"),
    avg_price_rub=("nominal_price_rub_amt","mean"),
    median_price_rub=("nominal_price_rub_amt","median"),
    p90_price_rub=("nominal_price_rub_amt", lambda s: np.nanpercentile(s.dropna(), 90) if s.notna().any() else np.nan)
).reset_index().sort_values("orders", ascending=False)
summary_by_type.to_csv(CFG.out_dir/"csv"/"summary_by_type.csv", index=False)
print("[saved] summary_by_type.csv")

monthly_type = (df.groupby(["order_month","order_type"]).size()
                  .reset_index(name="orders")
                  .sort_values(["order_month","order_type"]))
monthly_type.to_csv(CFG.out_dir/"csv"/"monthly_by_type.csv", index=False)
print("[saved] monthly_by_type.csv")

lead_summary = (df.groupby(["order_type","lead_bucket"])
                  .agg(orders=("order_rk","count"),
                       success_rate=("is_success","mean"),
                       avg_price=("nominal_price_rub_amt","mean"))
                  .reset_index()
                  .sort_values(["order_type","lead_bucket"]))
lead_summary.to_csv(CFG.out_dir/"csv"/"lead_summary.csv", index=False)
print("[saved] lead_summary.csv")

fig1, ax1 = plt.subplots()
pivot = (df.groupby(["order_month","order_type"])["order_rk"].count()
           .unstack(fill_value=0)
           .sort_index())
pivot.plot(ax=ax1, marker="o")
ax1.set_title("Динамика заказов по месяцам (по типам)")
ax1.set_xlabel("Месяц"); ax1.set_ylabel("Число заказов")
ax1.tick_params(axis='x', rotation=45)
for col in pivot.columns:
    y = pivot[col].iloc[-1]
    ax1.annotate(f"{_fmt_int(y)}", xy=(len(pivot)-1, y), xytext=(5, 5), textcoords="offset points", fontsize=9)
p1, s1 = savefig(fig1, "orders_by_month")

fig2, ax2 = plt.subplots()
sr = (df.groupby("order_type")["is_success"].mean().sort_values(ascending=False) * 100)
sr.plot(kind="bar", ax=ax2)
ax2.set_title("Доля успешных заказов (SUC), %")
ax2.set_xlabel("Тип заказа"); ax2.set_ylabel("% успешных")
for i, v in enumerate(sr.values):
    ax2.text(i, v + max(1, sr.max()*0.02), f"{v:.1f}%", ha="center", va="bottom", fontsize=10)
p2, s2 = savefig(fig2, "success_rate_by_type")

fig3, ax3 = plt.subplots(figsize=(9.6, 5.5))
if _HAS_SEABORN:
    sns.violinplot(data=df, x="order_type", y="nominal_price_rub_amt", cut=0, inner="quartile", ax=ax3)
    ax3.set_title("Распределение цены заказа, ₽ (виолины с квартилями)")
else:
    df.boxplot(column="nominal_price_rub_amt", by="order_type", ax=ax3)
    ax3.set_title("Цена заказа, ₽ (боксплот)")
    plt.suptitle("")
ax3.set_xlabel("Тип заказа"); ax3.set_ylabel("Цена, ₽")
p3, s3 = savefig(fig3, "price_distribution")

lead = df["lead_time_days"].dropna().clip(lower=-5, upper=60)
if lead.shape[0] > CFG.max_sample_hist:
    lead = lead.sample(CFG.max_sample_hist, random_state=CFG.random_state)
fig4, ax4 = plt.subplots()
ax4.hist(lead, bins=nice_bins(lead), edgecolor="white")
ax4.set_title("Лид-тайм бронирования (дней)")
ax4.set_xlabel("Дней от создания до начала поездки"); ax4.set_ylabel("Частота")
for q in [5, 25, 50, 75, 95]:
    v = np.percentile(lead, q)
    ax4.axvline(v, color="tab:red", lw=1, ls="--")
    ax4.text(v, ax4.get_ylim()[1]*0.95, f"P{q}={v:.0f}", rotation=90, ha="right", va="top", color="tab:red", fontsize=9)
p4, s4 = savefig(fig4, "lead_time_hist")

stay = df.loc[df.get("order_type_cd")=="HOT", "stay_nights"].dropna().clip(lower=0, upper=30)
fig5, ax5 = plt.subplots()
ax5.hist(stay, bins=nice_bins(stay), edgecolor="white")
ax5.set_title("Распределение длительности проживания (отели)")
ax5.set_xlabel("Ночей"); ax5.set_ylabel("Частота")
for q in [50, 90]:
    v = np.percentile(stay, q) if stay.shape[0] else np.nan
    if pd.notna(v):
        ax5.axvline(v, color="tab:red", lw=1, ls="--")
        ax5.text(v, ax5.get_ylim()[1]*0.95, f"P{q}={v:.0f}", rotation=90, ha="right", va="top", color="tab:red", fontsize=9)
p5, s5 = savefig(fig5, "stay_nights_hist")

lead_pivot = (df.groupby(["order_type","lead_bucket"])["is_success"].mean().unstack(fill_value=np.nan))
fig6, ax6 = plt.subplots()
(lead_pivot*100).T.plot(kind="bar", ax=ax6)
ax6.set_title("SUC-rate (%) по корзинам lead-time")
ax6.set_xlabel("Корзина lead-time"); ax6.set_ylabel("% SUC"); ax6.legend(title="Тип заказа")
plt.xticks(rotation=0)
p6, s6 = savefig(fig6, "success_by_lead_bucket")

heat = (df.groupby(["order_month","order_type"])["is_success"].mean().unstack())
fig7, ax7 = plt.subplots(figsize=(10, 5))
if _HAS_SEABORN:
    sns.heatmap(heat.T*100, annot=True, fmt=".1f", cmap="YlGnBu", cbar_kws={"label":"SUC, %"}, ax=ax7)
else:
    im = ax7.imshow((heat.T*100).fillna(0).values, aspect="auto", cmap="viridis")
    ax7.set_yticks(range(len(heat.columns))); ax7.set_yticklabels(heat.columns)
    ax7.set_xticks(range(len(heat.index)));   ax7.set_xticklabels(heat.index, rotation=45)
    fig7.colorbar(im, ax=ax7, label="SUC, %")
ax7.set_title("SUC-rate по месяцам и типам (теплокарта)")
p7, s7 = savefig(fig7, "heatmap_success_month_type")

fig8, ax8 = plt.subplots()
for t, sub in df.groupby("order_type"):
    x, y = ecdf(sub["nominal_price_rub_amt"].dropna().clip(lower=0, upper=np.nanpercentile(df["nominal_price_rub_amt"].dropna(), 99)))
    if len(x): ax8.plot(x, y, label=t)
ax8.set_title("ECDF цены (накоп. распределение)")
ax8.set_xlabel("Цена, ₽"); ax8.set_ylabel("Доля ≤ x"); ax8.legend()
p8, s8 = savefig(fig8, "price_ecdf")

tmp = df[["nominal_price_rub_amt","is_success","order_type"]].dropna()
tmp["price_decile"] = pd.qcut(tmp["nominal_price_rub_amt"], q=10, duplicates="drop")
dec = (tmp.groupby(["order_type","price_decile"])["is_success"].mean().reset_index())
def qmid(qstr: str) -> float:
    try: return (float(qstr.strip("()[]").split(",")[0]) + float(qstr.strip("()[]").split(",")[1])) / 2
    except: return 0.0
dec["mid"] = dec["price_decile"].astype(str).map(qmid)
fig9, ax9 = plt.subplots()
for t, sub in dec.sort_values("mid").groupby("order_type"):
    ax9.plot(sub["mid"], sub["is_success"]*100, marker="o", label=t)
ax9.set_title("SUC-rate vs цена (децили)"); ax9.set_xlabel("Середина децили цены, ₽")
ax9.set_ylabel("SUC, %"); ax9.legend()
p9, s9 = savefig(fig9, "success_vs_price_deciles")

wh = (df.groupby(["dow","hour"])["order_rk"].count().unstack(fill_value=0))
fig10, ax10 = plt.subplots(figsize=(10, 5))
if _HAS_SEABORN:
    sns.heatmap(wh, cmap="Blues", ax=ax10, cbar_kws={"label":"# заказов"})
else:
    im = ax10.imshow(wh.values, aspect="auto", cmap="Blues")
    fig10.colorbar(im, ax=ax10, label="# заказов")
    ax10.set_xticks(range(len(wh.columns))); ax10.set_xticklabels(wh.columns)
    ax10.set_yticks(range(len(wh.index)));   ax10.set_yticklabels(wh.index)
ax10.set_title("Активность заказов по дню недели и часу")
ax10.set_xlabel("Час"); ax10.set_ylabel("День недели (0=Пн)")
p10, s10 = savefig(fig10, "orders_by_dow_hour")

"""В этом блоке собраны более сложные и глубокие аналитические методики, которые дают детальное понимание пользовательского поведения. В отличие от базового EDA, здесь мы смотрим на данные под более специфическим углом:
1. Когортный анализ: Изучаем удержание (Retention) и пожизненную ценность (LTV) клиентов.
2. RFM-сегментация: Делим клиентов на группы по давности, частоте и сумме покупок, чтобы выявить самых ценных.
3. Анализ кросс-продаж: Выясняем, как часто клиенты покупают и авиабилеты, и отели.
Метрики активности: Считаем DAU/WAU/MAU для оценки вовлеченности аудитории.
"""

assert "client_rk" in df.columns, "Нужен client_rk для когорт."
clients = df[["client_rk","created_dttm","nominal_price_rub_amt"]].copy()
clients["order_month_p"] = clients["created_dttm"].dt.to_period("M")
clients["first_month"] = clients.groupby("client_rk")["order_month_p"].transform("min")

def period_diff_months(a: pd.Series, b: pd.Series) -> pd.Series:
    out = pd.Series(pd.NA, index=a.index, dtype="Int64")
    mask = a.notna() & b.notna()
    out.loc[mask] = (a[mask].astype("int") - b[mask].astype("int")).astype("int")
    return out
clients["month_idx"] = period_diff_months(clients["order_month_p"], clients["first_month"])

cln = clients.dropna(subset=["month_idx"]).copy()
cln["month_idx"] = cln["month_idx"].astype("int")

cohort_sizes = cln.drop_duplicates(["client_rk","first_month"]).groupby("first_month")["client_rk"].nunique()
active = cln.drop_duplicates(["client_rk","first_month","order_month_p"]).groupby(["first_month","month_idx"])["client_rk"].nunique().unstack(fill_value=0)
retention = active.div(cohort_sizes, axis=0).sort_index()
retention_13 = retention.iloc[:, :min(13, retention.shape[1])]

figR, axR = plt.subplots(figsize=(10.5, 5.5))
im = axR.imshow((retention_13*100).fillna(0).values, aspect="auto", cmap="YlGnBu", vmin=0, vmax=100)
axR.set_title("Retention когорт (%) — месяц 0..12 от первого заказа"); axR.set_xlabel("Месяц с момента старта когорты"); axR.set_ylabel("Когорта (месяц первого заказа)")
axR.set_xticks(range(retention_13.shape[1])); axR.set_xticklabels(list(range(retention_13.shape[1])))
axR.set_yticks(range(len(retention_13.index))); axR.set_yticklabels([str(p) for p in retention_13.index.astype(str)])
figR.colorbar(im, ax=axR, label="Retention, %")
pR, sR = savefig(figR, "cohort_retention")

rev = cln.groupby(["first_month","month_idx"])["nominal_price_rub_amt"].sum().unstack(fill_value=0).sort_index()
ltv = rev.cumsum(axis=1).div(cohort_sizes, axis=0)
avg_ltv = ltv.mean(axis=0)
figL, axL = plt.subplots(figsize=(9.6, 5.0))
for i, (cohort, row) in enumerate(ltv.iterrows()):
    if i % max(1, len(ltv)//10) == 0:
        axL.plot(row.index, row.values, alpha=0.25, lw=1)
axL.plot(avg_ltv.index, avg_ltv.values, color="tab:red", lw=2.5, label="Средняя LTV")
axL.set_title("LTV-кривая: накопленная выручка на пользователя (руб.)"); axL.set_xlabel("Месяц с момента старта когорты"); axL.set_ylabel("Рубли на пользователя"); axL.legend()
pL, sL = savefig(figL, "cohort_ltv")

#RFM Segmentation
required_cols = {"client_rk", "order_rk", "created_dttm", "nominal_price_rub_amt"}
if not (required_cols - set(df.columns)):
    rfm = (df.groupby("client_rk", dropna=False)
             .agg(last_order=("created_dttm", "max"), freq=("order_rk", "count"), monetary=("nominal_price_rub_amt", "sum"))
             .reset_index())
    rfm["recency_days"] = (df["created_dttm"].max() - rfm["last_order"]).dt.days
    rfm["R"] = qscore(rfm["recency_days"], q=5, reverse=True)
    rfm["F"] = qscore(rfm["freq"], q=5, reverse=False)
    rfm["M"] = qscore(rfm["monetary"], q=5, reverse=False)
    rfm["RFM_Score"] = rfm["R"].astype(str) + rfm["F"].astype(str) + rfm["M"].astype(str)
    rfm["AOV"] = rfm["monetary"] / rfm["freq"].replace(0, np.nan)
    rfm.to_csv(CFG.out_dir / "csv" / "rfm_table.csv", index=False)
    print("[saved] rfm_table.csv")

    top_rfm = rfm["RFM_Score"].value_counts().head(20).sort_values()
    figRFM1, axRFM1 = plt.subplots(figsize=(10, 6))
    axRFM1.barh(top_rfm.index, top_rfm.values); axRFM1.set_title("Топ RFM-сегментов по числу клиентов"); axRFM1.set_xlabel("Клиентов")
    for y, v in enumerate(top_rfm.values): axRFM1.text(v, y, f" {_fmt_int(v)}", va="center")
    pRFM1, sRFM1 = savefig(figRFM1, "rfm_top_segments")

    figRFM2, axRFM2 = plt.subplots(figsize=(9.5, 6))
    sizes = np.sqrt(rfm["AOV"].fillna(0).clip(lower=0)) * 6 + 10
    sc = axRFM2.scatter(rfm["freq"], rfm["monetary"], c=rfm["R"], cmap="viridis", s=sizes, alpha=0.6, linewidths=0)
    axRFM2.set_title("RFM: Frequency vs Monetary (цвет=R, размер≈√AOV)"); axRFM2.set_xlabel("Frequency (число заказов)"); axRFM2.set_ylabel("Monetary (суммарная выручка, ₽)")
    cb = plt.colorbar(sc, ax=axRFM2); cb.set_label("Recency score (R)")
    pRFM2, sRFM2 = savefig(figRFM2, "rfm_scatter")

#Cross-Sell
client_types = df.pivot_table(index="client_rk", columns="order_type_cd", values="order_rk", aggfunc="count", fill_value=0)
for col in ["AIR", "HOT"]:
    if col not in client_types.columns: client_types[col] = 0
client_types["has_air"] = (client_types["AIR"] > 0)
client_types["has_hot"] = (client_types["HOT"] > 0)
both = int((client_types["has_air"] & client_types["has_hot"]).sum())
only_air = int((client_types["has_air"] & ~client_types["has_hot"]).sum())
only_hot = int((~client_types["has_air"] & client_types["has_hot"]).sum())
neither = int((~client_types["has_air"] & ~client_types["has_hot"]).sum())
figXS, axXS = plt.subplots(figsize=(8.5, 4.6))
axXS.bar(["Только AIR", "Только HOT", "Оба", "Ни того, ни другого"], [only_air, only_hot, both, neither])
axXS.set_title("Кросс-селл: распределение клиентов по типам покупок"); axXS.set_ylabel("Клиентов")
for i, v in enumerate([only_air, only_hot, both, neither]): axXS.text(i, v + max(1, max([only_air, only_hot, both, neither]) * 0.01), f"{v:,}".replace(",", " "), ha="center", va="bottom")
pXS, sXS = savefig(figXS, "cross_sell_distribution")
cs_table = pd.DataFrame({
    "window_days": windows,
    "AIR→HOT_%": [round(x*100, 2) if pd.notna(x) else np.nan for x in shares_air_to_hot],
    "HOT→AIR_%": [round(x*100, 2) if pd.notna(x) else np.nan for x in shares_hot_to_air],
})
display(cs_table)

first_air = df.loc[df["order_type_cd"]=="AIR"].groupby("client_rk")["created_dttm"].min()
first_hot = df.loc[df["order_type_cd"]=="HOT"].groupby("client_rk")["created_dttm"].min()
delta_air_to_hot = (first_hot - first_air).dt.days
delta_hot_to_air = (first_air - first_hot).dt.days
windows = [3, 7, 14, 30]
def share_within(delta_series: pd.Series, window_days: int) -> float:
    mask_valid = delta_series.notna() & (delta_series >= 0)
    return float((delta_series[mask_valid] <= window_days).mean()) if mask_valid.sum() > 0 else np.nan
shares_air_to_hot = [share_within(delta_air_to_hot, w) for w in windows]
shares_hot_to_air = [share_within(delta_hot_to_air, w) for w in windows]
y1 = [x*100 if pd.notna(x) else 0 for x in shares_air_to_hot]
y2 = [x*100 if pd.notna(x) else 0 for x in shares_hot_to_air]
figXSp, axXSp = plt.subplots(figsize=(9, 4.8))
bars1 = axXSp.bar(np.arange(len(windows)) - 0.2, y1, width=0.4, label="AIR→HOT")
bars2 = axXSp.bar(np.arange(len(windows)) + 0.2, y2, width=0.4, label="HOT→AIR")
axXSp.set_title("Вероятность кросс-покупки в окно N дней от первой покупки, %"); axXSp.set_xticks(np.arange(len(windows))); axXSp.set_xticklabels(windows)
axXSp.set_xlabel("Окно (дней)"); axXSp.set_ylabel("% клиентов"); axXSp.legend()
for bars in (bars1, bars2):
    for b in bars: axXSp.text(b.get_x()+b.get_width()/2, b.get_height(), f"{b.get_height():.1f}%", ha="center", va="bottom", fontsize=9)
pXSp, sXSp = savefig(figXSp, "cross_sell_windowed_probs")
p_air_to_hot = share_within(delta_air_to_hot, 7); p_hot_to_air = share_within(delta_hot_to_air, 7)

#Simplified Funnel
funnel = (df.groupby(["order_type","lead_bucket"])["is_success"].agg(created="count", success="sum").reset_index())
funnel["suc_rate"] = funnel["success"] / funnel["created"]
figF, axF = plt.subplots(figsize=(10.5, 5.0))
for t, sub in funnel.groupby("order_type"):
    axF.plot(sub["lead_bucket"], sub["suc_rate"]*100, marker="o", label=t)
axF.set_title("Фаннел (упрощённый): SUC-rate по корзинам lead-time"); axF.set_xlabel("Корзина lead-time"); axF.set_ylabel("SUC, %"); axF.legend(); plt.xticks(rotation=0)
pF, sF = savefig(figF, "funnel_by_lead")

#Activity Metrics
df["date"] = df["created_dttm"].dt.date; df["week"] = df["created_dttm"].dt.to_period("W"); df["month"] = df["created_dttm"].dt.to_period("M")
DAU = df.groupby("date")["client_rk"].nunique(); WAU = df.groupby("week")["client_rk"].nunique(); MAU = df.groupby("month")["client_rk"].nunique()
stickiness = (DAU.groupby(pd.to_datetime(DAU.index).to_period("M")).mean() / MAU).fillna(0)
x_d, x_w, x_m, x_sm = pd.to_datetime(DAU.index), WAU.index.to_timestamp(), MAU.index.to_timestamp(), stickiness.index.to_timestamp()
figAct, axAct = plt.subplots(2, 1, figsize=(14, 8))
axAct[0].plot(x_d, DAU.values, label="DAU"); axAct[0].plot(x_w, WAU.values, label="WAU"); axAct[0].plot(x_m, MAU.values, label="MAU")
axAct[0].set_title("DAU / WAU / MAU — динамика"); axAct[0].set_ylabel("Уникальные клиенты"); axAct[0].legend()
axAct[1].bar(x_sm, stickiness.values, width=20, align="center")
axAct[1].set_title("Stickiness (средний DAU в месяце / MAU)"); axAct[1].set_ylabel("Доля"); axAct[1].yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(lambda v,_: f"{v:.0%}"))
for ax in axAct: ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))
figAct.autofmt_xdate(rotation=30)
savefig(figAct, "activity_metrics")

#ARPU & ARPPU
total_clients = df["client_rk"].nunique()
total_revenue = df["nominal_price_rub_amt"].sum()
paying_clients = df[df["nominal_price_rub_amt"] > 0]["client_rk"].nunique()
ARPU = (total_revenue / total_clients) if total_clients else 0
ARPPU = (total_revenue / paying_clients) if paying_clients else 0
print(f"💡 ARPU (выручка/клиент): {_fmt_int(ARPU)} ₽")
print(f"💡 ARPPU (выручка/платящего клиента): {_fmt_int(ARPPU)} ₽")
w = 7
p_air_to_hot_7 = shares_air_to_hot[windows.index(w)]
p_hot_to_air_7 = shares_hot_to_air[windows.index(w)]
print(f"[Кросс-селл за {w} дней] AIR→HOT ≈ {p_air_to_hot_7*100:.1f}% | HOT→AIR ≈ {p_hot_to_air_7*100:.1f}%")

"""Анализ данных бесполезен без выводов и предложений. Этот блок переводит результаты анализа на язык бизнеса.
Здесь мы:
1. Формулируем продуктовые гипотезы: На основе найденных инсайтов (например, о зависимости конверсии от цены) мы предлагаем конкретные идеи по улучшению продукта.
2. Выбираем лучшую гипотезу: Обосновываем, какую из идей стоит тестировать в первую очередь и почему.
3. Разрабатываем методику: Описываем, как можно было бы оценить долю сервиса на рынке, используя внутренние и внешние данные. Это показывает стратегический подход к аналитике.
"""

#Hypotheses
hypotheses = [
    "Показывать промо-коды пользователям с коротким лид-таймом (≤3 дня) → рост конверсии last-minute.",
    "Упростить оплату до one-click для лояльных (bundle Pro/Premium, участники LP) → рост SUC-rate, меньше дропа.",
    "Показывать пакеты «авиабилет+отель» в поиске/корзине → рост AOV и кросс-продаж."
]
best_hypothesis = hypotheses[2]
best_rationale = [
    "В данных есть совместный спрос: для части поездок логично брать и перелёт, и отель.",
    "Гипотеза даёт двойной эффект: ↑AOV + ↑кросс-продажи, измеряется простым A/B-тестом.",
    "Можно начать без тяжёлой персонализации (простые правила по датам/направлениям/цене).",
    "Primary metric: AOV; Secondary: % пакетов, CR поиск→покупка, отказ на оплате."
]

#Market Share
if "created_dttm" in df.columns:
    d24 = df[df["created_dttm"].dt.year == 2024]
    ms_air_suc = int(((d24["order_type_cd"]=="AIR") & (d24["is_success"])).sum())
    ms_hot_suc = int(((d24["order_type_cd"]=="HOT") & (d24["is_success"])).sum())
else:
    ms_air_suc = ms_hot_suc = 0

market_methodology_note = f"""
Оценка доли сервиса (эскиз методики):
  1) Зафиксировать период (например, 2024) и посчитать в нашем датасете:
     SUC_AIR={_fmt_int(ms_air_suc)}, SUC_HOT={_fmt_int(ms_hot_suc)}.
  2) Взять внешние агрегаты:
     Passengers_total (Росавиация), RoomNights_total (Росстат/отраслевые отчёты).
  3) Доли:
     доля_авиа ≈ SUC_AIR / Passengers_total,
     доля_отели ≈ SUC_HOT / RoomNights_total.
  4) Коррекции: мультисегментные билеты, отмены/возвраты, разница «пассажир vs заказ», сезонность.
"""

"""Результаты анализа нужно красиво упаковать и представить коллегам. Этот блок автоматизирует создание финальных отчетов. Он берет все построенные ранее графики и выводы и собирает из них два артефакта:
1. HTML-презентация: Генерируется полноценная веб-страница со слайдами, графиками и ключевыми выводами. Изображения встроены прямо в файл, поэтому его легко пересылать.
2. Jupyter-ноутбук (.ipynb): Создается файл ноутбука, который содержит весь код анализа. Это обеспечивает воспроизводимость исследования — любой другой аналитик сможет открыть его и повторить все шаги.
"""

#HTML Presentation
from pathlib import Path

TBRAND = {
    "bg": "#F5F6F8",
    "slide": "#FFFFFF",
    "text": "#111111",
    "muted": "#6B7280",
    "border": "#EAECEF",
    "yellow": "#FFDD2D",
    "yellowDark": "#E6C200",
    "shadow": "0 14px 40px rgba(17,17,17,.10)",
    "ok": "#10B981", "warn": "#F59E0B", "bad": "#EF4444",
}

WEBFONTS = """
<link href="https://fonts.googleapis.com/css2?family=Manrope:wght@500;700;800&family=Inter:wght@400;600&display=swap" rel="stylesheet">
"""

def _build_css(C=TBRAND):
    return f"""
*{{box-sizing:border-box}} html,body{{height:100%}}
body{{margin:0;background:{C['bg']};color:{C['text']};font-family:Manrope,Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif}}

.slide{{width:1280px;height:720px;margin:24px auto;padding:54px 60px 50px;background:{C['slide']};
  border:1px solid {C['border']};border-radius:24px;box-shadow:{C['shadow']};position:relative;overflow:hidden}}
.slide.has-brand{{padding-top:120px}}
.brand-bar{{position:absolute;left:0;top:0;right:0;height:72px;background:{C['yellow']};border-bottom:1px solid rgba(0,0,0,.06)}}

.brand-corner{{position:absolute;right:-120px;bottom:-120px;width:340px;height:340px;border-radius:50%;
  background:radial-gradient(closest-side,rgba(255,221,45,.22),transparent 70%)}}

h1.title{{margin:0;font-size:44px;line-height:1.12;font-weight:800;letter-spacing:.1px}}
.subtitle{{margin-top:10px;color:{C['muted']};font-size:18px}}
.title-underline{{width:72px;height:6px;background:{C['yellow']};border-radius:3px;margin:12px 0 8px}}

.hr{{height:2px;background:{C['border']};margin:16px 0 18px}}

.grid{{display:grid;gap:16px}}
.grid.two{{grid-template-columns:1fr 1fr}}
.grid.three{{grid-template-columns:1fr 1fr 1fr}}
.grid.four{{grid-template-columns:1fr 1fr 1fr 1fr}}

.card{{background:#fff;border:1px solid {C['border']};border-radius:16px;padding:14px;min-height:140px;box-shadow:0 6px 24px rgba(17,17,17,.06)}}
.card h3{{margin:0 0 8px;font-size:18px;font-weight:700}}
.card p.caption{{margin:6px 0 0;color:{C['muted']};font-size:14px}}
.card img{{width:100%;height:360px;object-fit:contain;background:#FAFBFC;border-radius:12px;border:1px solid {C['border']}}}

.kpi-row{{display:flex;gap:12px;flex-wrap:wrap;margin-top:10px}}
.kpi{{flex:1 1 0;min-width:220px;background:#fff;border:1px solid {C['border']};border-radius:16px;padding:12px 14px;box-shadow:0 6px 24px rgba(17,17,17,.06)}}
.kpi .label{{color:{C['muted']};font-size:13px;margin-bottom:4px}}
.kpi .value{{font-size:28px;font-weight:800;letter-spacing:.2px}}
.kpi.ok .value{{color:{C['ok']}}} .kpi.warn .value{{color:{C['warn']}}} .kpi.bad .value{{color:{C['bad']}}}

.chips{{display:flex;gap:8px;flex-wrap:wrap;margin:8px 0 4px}}
.chip{{background:{C['yellow']};border:1px solid rgba(0,0,0,.06);border-radius:999px;padding:6px 10px;font-weight:700;font-size:12px}}
.note{{background:#FFFBEA;border:1px solid {C['yellowDark']};border-left:6px solid {C['yellowDark']};border-radius:12px;padding:12px 14px;color:{C['text']};font-size:14px}}

ul.bullets{{padding-left:18px;margin:8px 0 0}}
ul.bullets li{{margin:6px 0;color:{C['text']}}}
ul.bullets li::marker{{color:{C['yellowDark']}}}

.table{{width:100%;border-collapse:collapse;margin-top:8px}}
.table th,.table td{{border:1px solid {C['border']};padding:8px 10px;text-align:left}}
.table th{{background:#FAFBFC}}
.table .r{{text-align:right}}

.footer{{position:absolute;left:0;right:0;bottom:16px;display:flex;justify-content:space-between;padding:0 24px;color:{C['muted']};font-size:12.5px}}
.footer .brand{{font-weight:700}}

@media print{{@page{{size:1280px 720px;margin:0}} .slide{{page-break-after:always;box-shadow:none;margin:0 auto}}}}
"""

def _esc(s):
    return "" if s is None else str(s).replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")

def card_img(img_path, caption=""):
    return f"""<div class="card"><img src="{_esc(img_path)}" alt="{_esc(caption)}"/><p class="caption">{_esc(caption)}</p></div>"""

def _bullets(items):
    if not items: return ""
    return "<ul class='bullets'>" + "\n".join(f"<li>{_esc(x)}</li>" for x in items) + "</ul>"

def html_cover(title, subtitle="", badge="Аналитическая записка"):
    return f"""
<section class="slide has-brand">
  <div class="brand-bar"></div>
  <div style="position:absolute; right:26px; top:18px;" class="chip">{_esc(badge)}</div>
  <h1 class="title">{_esc(title)}</h1>
  <div class="subtitle">{_esc(subtitle)}</div>
  <div class="brand-corner"></div>
  <div class="footer"><span class="brand">T-Bank · Product Analytics</span><span>Cover</span></div>
</section>"""

def html_kpis(title, kpis, bullets=None, subtitle="", chips=None):
    kpi_html = "".join([
        f"""<div class="kpi {'ok' if k.get('tone')=='ok' else 'warn' if k.get('tone')=='warn' else 'bad' if k.get('tone')=='bad' else ''}">
              <div class="label">{_esc(k.get('label',''))}</div>
              <div class="value">{_esc(k.get('value',''))}</div>
            </div>""" for k in kpis
    ])
    chips_html = "" if not chips else "<div class='chips'>" + "".join(f"<span class='chip'>{_esc(c)}</span>" for c in chips) + "</div>"
    return f"""
<section class="slide">
  <div class="title-underline"></div><h1 class="title">{_esc(title)}</h1>
  {f'<div class="subtitle">{_esc(subtitle)}</div>' if subtitle else ''}{chips_html}
  <div class="kpi-row">{kpi_html}</div>{_bullets(bullets)}
  <div class="footer"><span class="brand">T-Bank</span><span>KPIs</span></div>
</section>"""

def html_section(title, bullets=None, note=None, subtitle="", cols=2, cards=None, chips=None):
    grid_class = "two" if cols==2 else "three" if cols==3 else "four"
    chips_html = "" if not chips else "<div class='chips'>" + "".join(f"<span class='chip'>{_esc(c)}</span>" for c in chips) + "</div>"
    cards_html = "".join(cards or [])
    return f"""
<section class="slide">
  <div class="title-underline"></div><h1 class="title">{_esc(title)}</h1>
  {f'<div class="subtitle">{_esc(subtitle)}</div>' if subtitle else ''}{chips_html}
  {_bullets(bullets)}
  {'<div class="note">'+_esc(note)+'</div>' if note else ''}
  <div class="hr"></div>
  <div class="grid {grid_class}">{cards_html}</div>
  <div class="footer"><span class="brand">T-Bank</span><span>{_esc(title[:24])}</span></div>
</section>"""

def html_slide(title, bullets=None, grid_imgs=None, subtitle="", chips=None):
    return html_section(title, bullets=bullets, subtitle=subtitle, cols=2, cards=grid_imgs, chips=chips)

def html_compact_hypotheses(hyp_list, best_title, best_points, share_rows):
    """
    hyp_list: [str, str, str]
    best_title: str
    best_points: [str, str, ...]
    share_rows: list of rows for table: [(label, our, market, share), ...]
    """
    table_rows = "".join([
        f"<tr><td>{_esc(lbl)}</td><td class='r'>{_esc(our)}</td><td class='r'>{_esc(mkt)}</td><td class='r'>{_esc(sh)}</td></tr>"
        for (lbl, our, mkt, sh) in share_rows
    ])
    return f"""
<section class="slide">
  <div class="title-underline"></div><h1 class="title">Гипотезы → Лучшая → Доля сервиса</h1>
  <div class="grid three">
    <div class="card">
      <h3>Гипотезы для A/B</h3>
      {_bullets(hyp_list)}
      <p class="caption">Метрики: CR cross-sell, ARPU, LTV 60–90д</p>
    </div>
    <div class="card">
      <h3>{_esc(best_title)}</h3>
      {_bullets(best_points)}
      <div class="note">Ожидаемый эффект: +CR cross-sell 1.3–1.8×; вторично — рост удержания</div>
    </div>
    <div class="card">
      <h3>Оценка доли сервиса (черновая)</h3>
      <table class="table">
        <thead><tr><th>Сегмент</th><th class='r'>Наши успехи</th><th class='r'>Рынок</th><th class='r'>Доля</th></tr></thead>
        <tbody>{table_rows}</tbody>
      </table>
      <p class="caption">Допущение: 1 заказ ≈ 1 пассажир/1 проживание</p>
    </div>
  </div>
  <div class="footer"><span class="brand">T-Bank</span><span>Summary</span></div>
</section>"""

def build_html_document(doc_title, slides):
    css = _build_css()
    head = f"""<!doctype html><html lang="ru"><head>
<meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>{_esc(doc_title)}</title>
{WEBFONTS}<style>{css}</style></head><body>"""
    foot = "</body></html>"
    return head + "\n".join(slides) + foot

def save_presentation(slides, title="T-Bank · Аналитическая записка", out_path="tbank_report.html"):
    out = Path(out_path)
    out.write_text(build_html_document(title, slides), encoding="utf-8")
    print(f"[saved] {out.resolve()}")
    return str(out.resolve())

try: slides_html
except NameError: slides_html = []

slides_html.append(html_cover(
    title="Путешествия T-Bank: EDA, гипотезы, доля сервиса",
    subtitle="Отели и авиабилеты · когортный анализ, RFM, кросс-селл, SUC-rate",
    badge="Аналитическая записка"
))

suc_air = float(df.loc[df["order_type_cd"] == "AIR", "is_success"].mean() * 100)
suc_hot = float(df.loc[df["order_type_cd"] == "HOT", "is_success"].mean() * 100)

avg_check = float(df["nominal_price_rub_amt"].mean())

mau = int(df["month"].dropna().groupby(df["month"]).apply(lambda s: df.loc[s.index, "client_rk"].nunique()).iloc[-1]) \
      if "month" in df.columns and len(df["month"].dropna()) else 0

try:
    mau = int(MAU.iloc[-1])
except Exception:
    pass

try:
    stickiness_last = float(stickiness.iloc[-1])
except Exception:
    last_m = df["created_dttm"].dt.to_period("M").max()
    dau_last_month = (df.loc[df["created_dttm"].dt.to_period("M") == last_m]
                        .groupby(df["created_dttm"].dt.date)["client_rk"].nunique()).mean()
    stickiness_last = (dau_last_month / mau) if mau else 0.0

orders_by_month = df["created_dttm"].dt.to_period("M").value_counts().sort_index()
season_peak = str(orders_by_month.idxmax()) if len(orders_by_month) else "—"

revenue_per_user = df.groupby("client_rk")["nominal_price_rub_amt"].sum().sort_values(ascending=False)
if len(revenue_per_user):
    cum = revenue_per_user.cumsum() / revenue_per_user.sum()
    core_share = float((cum < 0.72).mean())
    core_rev_target = 0.72
else:
    core_share, core_rev_target = 0.0, 0.0

tone_air = "ok" if suc_air >= 25 else "warn"
tone_hot = "ok" if suc_hot >= 25 else "warn"

slides_html.append(html_kpis(
    title="Сводные метрики",
    subtitle=f"Период: {period[0]} — {period[1]}",
    kpis=[
        {"label": "SUC-rate (AIR)", "value": f"{suc_air:.1f}%", "tone": tone_air},
        {"label": "SUC-rate (HOT)", "value": f"{suc_hot:.1f}%", "tone": tone_hot},
        {"label": "Средний чек, ₽",  "value": f"{avg_check:,.0f}".replace(",", " ")},
        {"label": "MAU / Stickiness", "value": f"{mau:,}".replace(",", " ") + f" / {stickiness_last:.1%}"}
    ],
    bullets=[
        f"Пик сезона: {season_peak}",
        "Lead-time > 21 дней → рост SUC (особенно в AIR)",
        f"RFM: ядро ≈ {core_share:.1%} клиентов → ~{int(core_rev_target*100)}% выручки"
    ],
    chips=["AIR", "HOT", str(pd.to_datetime(df['created_dttm'].min()).year) if df['created_dttm'].notna().any() else ""]
))


slides_html.append(html_slide("Когортный анализ", grid_imgs=[card_img(pR,"Retention когорт"), card_img(pL,"LTV-кривые")]))
slides_html.append(html_slide("RFM-сегментация", grid_imgs=[card_img(pRFM1,"Топ сегменты"), card_img(pRFM2,"F×M, цвет=R")]))
slides_html.append(html_slide("Кросс-селл AIR↔HOT", grid_imgs=[card_img(pXS,"Распределение клиентов"), card_img(pXSp,"Окна 3/7/14/30 дней")]))

MARKET_AIR_2024 = 111_700_000
MARKET_HOT_2024 = 390_200_000


d24 = df[df["created_dttm"].dt.year == 2024] if df["created_dttm"].notna().any() else df.iloc[0:0]
air_suc_24 = int(((d24["order_type_cd"] == "AIR") & (d24["is_success"])).sum())
hot_suc_24 = int(((d24["order_type_cd"] == "HOT") & (d24["is_success"])).sum())

air_share = (air_suc_24 / MARKET_AIR_2024) if MARKET_AIR_2024 else None
hot_share = (hot_suc_24 / MARKET_HOT_2024) if MARKET_HOT_2024 else None

share_rows = [
    ("Авиа",  _fmt_int(air_suc_24),
              _fmt_int(MARKET_AIR_2024) if MARKET_AIR_2024 else "—",
              _fmt_pct(air_share) if air_share is not None else "—"),
    ("Отели", _fmt_int(hot_suc_24),
              _fmt_int(MARKET_HOT_2024) if MARKET_HOT_2024 else "—",
              _fmt_pct(hot_share) if hot_share is not None else "—"),
]

slides_html.append(html_compact_hypotheses(
    hyp_list=[
        "Бандл «перелёт+отель» со скидкой 5–7% ↑ cross-sell (AIR→HOT)",
        "Смарт-ранжирование по lead-time (ранние — гибкие тарифы)",
        "RFM-персонализация: ядру — премиум пакеты; новичкам — кэшбэк"
    ],
    best_title="Почему бандл «перелёт+отель» — №1",
    best_points=[
        "В данных есть кросс-переходы в окнах 7–14 дней",
        "Единая корзина/чек ↓ фрикцию → ↑ CR и AOV",
        "A/B: скидка 5/7/10%, триггер ≤ 48 ч, таргет по RFM"
    ],
    share_rows=share_rows
))
out_html = save_presentation(slides_html,
                             title="T-Bank · Аналитическая записка",
                             out_path="tbank_report.html")
print("Готово:", out_html)

#Jupyter Notebook
nb_cells = [
    new_markdown_cell("# Т-Банк: отели и авиабилеты — EDA\n"
                      f"**Файл:** `{CFG.csv_path}` **Период:** {period[0]} — {period[1]}"),
    new_code_cell(textwrap.dedent(f"""
        import pandas as pd, numpy as np, matplotlib.pyplot as plt
        {'import seaborn as sns; sns.set_theme(context="notebook", style="ticks")' if _HAS_SEABORN else ''}
        df = pd.read_csv("{CFG.csv_path}", sep="{CFG.sep}", encoding="{CFG.encoding}", low_memory=False)


        DATE_COLS = {DATE_COLS}
        for c in DATE_COLS:
            if c in df.columns: df[c] = pd.to_datetime(df[c], errors="coerce")

        NUM_COLS = {NUM_COLS}
        def coerce_numeric(s):
            return pd.to_numeric(s.astype(str).str.replace(" ","").str.replace("\\xa0","").str.replace(",", "."),
                                 errors="coerce")
        for c in NUM_COLS:
            if c in df.columns: df[c] = coerce_numeric(df[c])


        FLAG_COLS = [c for c in df.columns if c.endswith("_flg")]
        for c in FLAG_COLS:
            df[c] = pd.to_numeric(df[c].astype(str).str.replace(",", "."), errors="coerce")
            df[c] = (df[c].fillna(0) > 0)


        df["order_type"] = df.get("order_type_cd").map({{"AIR":"Авиабилеты","HOT":"Отели"}}).fillna(df.get("order_type_cd"))
        df["is_success"] = df.get("order_status_cd","").eq("SUC")
        df["order_month"] = df["created_dttm"].dt.to_period("M").astype(str)


        df["lead_time_days"] = (df["book_start_dttm"] - df["created_dttm"]).dt.days if "book_start_dttm" in df.columns else np.nan
        if "book_end_dttm" in df.columns and "book_start_dttm" in df.columns:
            df["stay_nights"] = (df["book_end_dttm"] - df["book_start_dttm"]).dt.days
            df.loc[df.get("order_type_cd")!="HOT", "stay_nights"] = np.nan

        df.info()
    """)),
    new_markdown_cell("## Сводка и графики"),
    new_code_cell('df.groupby("order_type").agg(orders=("order_rk","count"), success_rate=("is_success","mean"), avg_price_rub=("nominal_price_rub_amt","mean"))'),
    new_code_cell('df.groupby(["order_month","order_type"])["order_rk"].count().unstack(fill_value=0).plot(marker="o"); plt.title("Динамика заказов по месяцам"); plt.xticks(rotation=45); plt.tight_layout()'),
    new_code_cell('(df.groupby("order_type")["is_success"].mean()*100).plot(kind="bar"); plt.title("SUC-rate, %"); plt.tight_layout()'),
    new_markdown_cell("## Гипотезы\n" + "\n".join([f"- {h}" for h in hypotheses]) + "\n\n**Выбор:** " + best_hypothesis)
]
nb = new_notebook(cells=nb_cells, metadata={"language_info":{"name":"python","version":sys.version.split()[0]}})
with open(CFG.ipynb_path, "w", encoding="utf-8") as f: nbf.write(nb, f)
print(f"[saved] ipynb → {CFG.ipynb_path.resolve()}")

"""Финальный и самый простой блок. Его единственная задача — сообщить пользователю, что скрипт успешно завершил свою работу. Он выводит в консоль подтверждающее сообщение и, что самое важное, полные пути к созданным файлам (HTML-отчету и Jupyter-ноутбуку), чтобы их можно было легко найти и открыть."""

print("\n=== Готово ===")
print("Папка с результатами:", CFG.out_dir.resolve())
print("Слайды (HTML):", CFG.html_path.resolve())
print("Ноутбук (.ipynb):", CFG.ipynb_path.resolve())